{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 知识工程-作业6 英文评论情感分类\n",
    "\n",
    "2024214500 叶璨铭\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码与文档格式说明\n",
    "\n",
    "> 本文档使用Jupyter Notebook编写，所以同时包括了实验文档和实验代码。\n",
    "\n",
    "> 本次实验项目采用了类似于 Quarto + nbdev 的方法来同步Jupyter Notebook代码到python文件, 因而我们的实验文档导出为pdf和html格式可以进行阅读，而我们的代码也导出为python模块形式，可以作为代码库被其他项目使用。\n",
    "我们这样做的好处是，避免单独管理一堆 .py 文件，防止代码冗余和同步混乱，py文件和pdf文件都是从.ipynb文件导出的，可以保证实验文档和代码的一致性。\n",
    "\n",
    "> 本文档理论上支持多个格式，包括ipynb, html, docx, pdf, md 等，但是由于 quarto和nbdev 系统的一些bug，我们目前暂时只支持ipynb, docx, pdf文件，以后有空的时候解决bug可以构建一个[在线文档网站](https://thu-coursework-machine-learning-for-big-data-docs.vercel.app/)。您在阅读本文档时，可以选择您喜欢的格式来进行阅读，建议您使用 Visual Studio Code (或者其他支持jupyter notebook的IDE, 但是VSCode阅读体验最佳) 打开 `ipynb`格式的文档来进行阅读。\n",
    "\n",
    "\n",
    "> 为了记录我们自己修改了哪些地方，使用git进行版本控制，这样可以清晰地看出我们基于助教的代码在哪些位置进行了修改，有些修改是实现了要求的作业功能，而有些代码是对助教的代码进行了重构和优化。我将我在知识工程课程的代码，在作业截止DDL之后，开源到 https://github.com/2catycm/THU-Coursework-Knowledge-Engineering.git ，方便各位同学一起学习讨论。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码规范说明\n",
    "\n",
    "为了让代码清晰规范，在作业开始前，使用 `ruff format`格式化助教的代码; 在我们实现函数过程中，函数的docstring应当遵循fastai规范而不是numpy规范，这样简洁清晰，不会Repeat yourself。\n",
    "\n",
    "![alt text](image.png)\n",
    "\n",
    "\n",
    "同时注意到VSCode-Pylance插件的报错\n",
    "\n",
    "![alt text](image-1.png)\n",
    "\n",
    "我们需要安装 AllenNLP，打开 https://github.com/allenai/allennlp，可以发现 “This repository was archived by the owner on Dec 17, 2022. It is now read-only.” 也就是说 AllenNLP 不再更新，是个比较老旧的库。\n",
    "\n",
    "allennlp是\"An Apache 2.0 NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks.\", PyTorch写的NLP库，而Elmo则是其支持的一个算法。\n",
    "\n",
    "我们服务器空间有限，为了避免单独为了allennlp重新安装老旧的PyTorch占满磁盘空间，决定手动修改 requirements.txt\n",
    "\n",
    "```bash\n",
    "git submodule add https://github.com/allenai/allennlp.git\n",
    "cd allennlp\n",
    "vim requirements.txt\n",
    "conda activate yuequ\n",
    "pip install -e .\n",
    "```\n",
    "发现 git 版本其实优于 pypi 版本，实际上没有改 requirements.txt 就可以增量安装。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原理回顾和课件复习\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "课上详细介绍了情感分析/观点挖掘任务的一些基本特点和难点，然后详细介绍了RNN的发展历程，最后提及了一下大模型方法FinGPT。\n",
    "\n",
    "之前我们学的词向量不能解决一词多义，这次用Elmo可能会厉害一些。\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "\n",
    "由于download.sh 的清华网盘链接过期，使用师兄群里发的文件\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "由于 /home 空间不足，使用软链接\n",
    "\n",
    "```bash\n",
    "cd 6.英文评论情感分类的作业\n",
    "rm -rf data\n",
    "ln -s /data/ycm/assignments/data\n",
    "cd data\n",
    "mv 第六章数据文件.zip data.zip\n",
    "unzip data.zip\n",
    "mv 第六章数据文件/* ./\n",
    "rm -rf 第六章数据文件/\n",
    "rm -rf data.zip\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载\n",
    "\n",
    "\n",
    "\n",
    "我们看下 main.py 文件\n",
    "\n",
    "使用到数据的地方是\n",
    "\n",
    "```python\n",
    "from data_util import MyDataset, collate_fn\n",
    "...\n",
    "MyDataset(\n",
    "        \"./data/train.tsv\",\n",
    "        max_length=max_length,\n",
    "        train=True,\n",
    "        max_example_num=max_train_example,\n",
    "    ),\n",
    "collate_fn=functools.partial(collate_fn, device=device),\n",
    "```\n",
    "\n",
    "助教已经帮我们实现了 collate_fn 关键是我们要写 MyDataset \n",
    "\n",
    "首先注意到 MyDataset[i] 返回的是一个元组，包含文本和标签\n",
    "\n",
    "```python\n",
    "def __getitem__(self, item):\n",
    "    return self.text[item], self.label[item]\n",
    "```\n",
    "\n",
    "需要自己有list来存。现在可以写 load \n",
    "\n",
    "我们需要观察一下数据格式\n",
    "\n",
    "![alt text](image-2.png)\n",
    "\n",
    "train.tsv 和 dev.tsv 都是  “sentence label”，test.tsv 是 “index sentence”， 这次作业 main.py 只要求我们做 train 和 dev的,c传递的参数都是 train=True。\n",
    "\n",
    "注意 csv 是 \"comma separated values\" 的缩写，tsv 是 \"tab separated values\" 的缩写，csv文件的分隔符是逗号，而tsv文件的分隔符是制表符（tab），所以我们需要使用 `sep=\"\\t\"` 来读取数据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfe5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import torch\n",
    "def load(\n",
    "    self,\n",
    "    file: str,  # file path\n",
    "    train: bool = True,  # whether is training file\n",
    ") -> Tuple[List[List[str]], List[int]]:  # Returns (text, label), text input and label\n",
    "    \"\"\"\n",
    "    load file into texts and labels\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # 使用pandas读取文件，自动推断分隔符\n",
    "    try:\n",
    "        # 首先尝试tab分隔符，因为这是期望的格式\n",
    "        df = pd.read_csv(file, sep='\\t')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file with tab separator: {e}\")\n",
    "        print(\"Trying to read with auto-detected separator...\")\n",
    "        # 如果失败，让pandas尝试自动推断分隔符\n",
    "        df = pd.read_csv(file, sep=None, engine='python')\n",
    "\n",
    "    text = df['sentence'].astype(str).tolist()\n",
    "    # 分词\n",
    "    text = [sentence.split() for sentence in text]\n",
    "    \n",
    "    if train:\n",
    "        # 训练集格式: sentence  label\n",
    "        label = df['label'].astype(int).tolist()\n",
    "    else:\n",
    "        # 测试集可能没有标签，默认为 -1 表示不知道\n",
    "        label = [-1] * len(text)\n",
    "        \n",
    "    return text, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4727e7c0",
   "metadata": {},
   "source": [
    "注意助教对  Returns (text, label), text input and label 的类型标注有误。\n",
    "\n",
    "首先label应该是 List[int] 类型，参考官方文档 https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html ，可以是float，但是不应该是str类型。\n",
    "\n",
    "其次text不应该是 List[str], 这里我们需要查看allennlp的 batch_to_ids 函数的约定 https://github.com/allenai/allennlp/blob/main/allennlp/modules/elmo.py ，可以看到其要求的输入是 List[List[str]], 也就是说需要对句子进行分词！\n",
    "\n",
    "\n",
    "![](image-3.png)\n",
    "\n",
    "我们差点就被原本的注释带偏啦，还好检查了allennlp的文档。\n",
    "\n",
    "\n",
    "分词并不难，因为这次作业是 “英文评论情感分类”，可以直接按照空白符分词，使用 `str.split()` 就可以了，不需要上次那样用结巴分词。\n",
    "\n",
    "当然，如果做得细致些，应该用 elmo 的 tokenier 去做分词，或者用nltk。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daba44c",
   "metadata": {},
   "source": [
    "现在可以实现 pad 函数\n",
    "\n",
    "事实上，刚才我们看了源码知道，allennlp的elmo已经实现了padding，会根据句子和单词的最大长度来补齐，实际上我们不应该做任何操作！\n",
    "\n",
    "当然，助教给了我们一个 max_length 的参数，实际上是用来限制句子长度的，超过这个长度的句子会被截断, 如果比elmo从数据发现的最大长度还要长，那多补一些也无妨，我们还是能实现一个。\n",
    "\n",
    "不过最重要的问题是，pad token是什么？上一次作业是助教定义的词库，传入了pad和unknown的id，这次作业我们需要遵循allennlp的elmo的约定！\n",
    "\n",
    "这下我们不得不继续查看源码 https://github.com/allenai/allennlp/blob/main/allennlp/modules/elmo.py\n",
    "\n",
    "![](image-4.png)\n",
    "\n",
    "这下可以确认pad token是0，从而实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44428b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(self, \n",
    "        text_ids: torch.Tensor,  # size N*L*D\n",
    "        )-> torch.Tensor: # Returns padded_text_id, size N*max_length*D\n",
    "    \"\"\"\n",
    "    pad text_ids to max_length\n",
    "    \"\"\"\n",
    "    N, L, D = text_ids.shape\n",
    "    if L >= self.max_length:\n",
    "        # 如果文本长度大于等于最大长度，截断\n",
    "        return text_ids[:, :self.max_length, :]\n",
    "    else:\n",
    "        # 如果文本长度小于最大长度，填充\n",
    "        padding = torch.zeros(N, self.max_length - L, D, dtype=text_ids.dtype, device=text_ids.device)\n",
    "        padded_text_ids = torch.cat([text_ids, padding], dim=1)\n",
    "        return padded_text_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118365f2",
   "metadata": {},
   "source": [
    "测试一下, 用 https://github.com/google-deepmind/treescope 看清楚数据是什么样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a33c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import treescope\n",
    "treescope.basic_interactive_setup(autovisualize_arrays=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab11814",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(\"./data/dev.tsv\")\n",
    "t, l = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7602eeb",
   "metadata": {},
   "source": [
    "## CNN 神经网络实现\n",
    "\n",
    "这次的TextCNN和第四次作业的基本一样，只是embedding换成了allennlp的elmo representation，然后分类数量换成了2，其他的都一样。\n",
    "\n",
    "上次我写得代码已经比较优雅高效，更多关于这段代码的理解和实现逻辑参阅 上次作业报告 https://github.com/2catycm/THU-Coursework-Knowledge-Engineering/blob/master/4.%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E4%BD%9C%E4%B8%9A/P_homework4.ipynb \n",
    "\n",
    "这次我们增加一个dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f52e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        options_file:str, # elmo file\n",
    "        weight_file:str, # elmo weight file\n",
    "        vector_size:int, # word embedding dim\n",
    "        filter_size:List[int]=[2, 3, 4, 5], # kernel size for each layer of CNN\n",
    "        channels:int=64, # output channel for CNN\n",
    "        max_length:int =1024, # max length of input sentence\n",
    "        dropout = 0.5, # dropout rate\n",
    "    ):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.embedding = Elmo(options_file, weight_file, 1, dropout=0)\n",
    "        ####################\n",
    "        # 初始化嵌入层已经通过Elmo完成\n",
    "        # 直接用上次作业的代码\n",
    "        # Build a stack of 1D CNN layers for each filter size\n",
    "        self.convs = nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv1d(in_channels=vector_size, \n",
    "                          out_channels=channels, \n",
    "                          kernel_size=k)\n",
    "                # Conv1dViaConv2d(\n",
    "                #     in_channels=vector_size,\n",
    "                #     out_channels=channels,\n",
    "                #     kernel_size=k,\n",
    "                #     conv_2d=KAN_Convolutional_Layer,\n",
    "                # )\n",
    "                for k in filter_size\n",
    "            ]\n",
    "        )\n",
    "        # Final linear layer for label prediction; number of classes equals len(label2index)\n",
    "        # CNN的输出通道数 × 不同卷积核的数量\n",
    "        self.linear = nn.Linear(channels * len(filter_size), 2) # 二分类问题（正面/负面）\n",
    "        #  Dropout层，防止过拟合\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.max_length = max_length\n",
    "    def forward(self, \n",
    "        inputs:torch.Tensor, # input sentence, size N*L\n",
    "        ) -> torch.Tensor: # predicted_logits: torch.tensor of size N*C (number of classes)\n",
    "        # 获取ELMo嵌入表示\n",
    "        inputs = self.embedding(inputs)[\"elmo_representations\"][0]  # [N, L, vector_size]\n",
    "        \n",
    "        # Convolutional layer\n",
    "        x = inputs.transpose(1, 2)  # 卷积需要将词向量维度放在最后 (N*D*L)\n",
    "        x = [conv(x) for conv in self.convs]\n",
    "        x = [nn.functional.gelu(i) for i in x]  # 每一个 i是 (N*C*Li) ， Li = L - ki + 1\n",
    "        # Pooling layer\n",
    "        x = [\n",
    "            nn.functional.max_pool1d(\n",
    "                i,\n",
    "                kernel_size=i.size(2),  # 对 Li 去做 max_pooling\n",
    "            ).squeeze(2)\n",
    "            for i in x  # 每一个 i是 (N*C*Li)\n",
    "        ]  # 每一个 item 变为 (N*C)\n",
    "        # Concatenate all pooling results\n",
    "        x = torch.cat(x, dim=1)  # 把每一个 item 拼接起来，变为 (N, C*len(filter_size))\n",
    "        # 应用dropout\n",
    "        x = self.dropout(x)\n",
    "        # Linear layer\n",
    "        x = self.linear(x)  # 分类，得到 (N*K)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a20f1",
   "metadata": {},
   "source": [
    "其中我们还用了 Conv2d兼容层，来尝试实现 KAN Conv，但是并没有成功，这次老师讲解的重点是RNN，所以今天我们不过多探索Kolmogorov–Arnold Networks。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc0eef",
   "metadata": {},
   "source": [
    "## RNN 神经网络实现\n",
    "\n",
    "### LSTM 实现\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e21590",
   "metadata": {},
   "source": [
    "### RWKV 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa0390",
   "metadata": {},
   "source": [
    "## 运行效果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516992bd",
   "metadata": {},
   "source": [
    "首先我们直接运行一下CNN，为了让速度快一些，我改了batch size为16\\*64，learning rate也\\*16。\n",
    "\n",
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=1 python main.py\n",
    "```\n",
    "\n",
    "![](image-5.png)\n",
    "\n",
    "可以看到效果一般，只到80。\n",
    "\n",
    "我们把batch size换回 64 再跑一次\n",
    "\n",
    "\n",
    "在跑之前，我们修改一下 main.py 代码，第一，老规矩啦，要支持argparse；第二这一次助教用了tqdm，但是中间完全没有反馈，根本看不到网络训练地好不好，不知道刚才80的问题在哪，所以我们加上loss和acc的反馈\n",
    "\n",
    "```python\n",
    "out_bar = tqdm(range(total_epoch))\n",
    "for epoch in out_bar: \n",
    "    ...\n",
    "    bar = tqdm(train_loader)\n",
    "    for text, label in bar:\n",
    "        ...\n",
    "        bar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "    ...\n",
    "    out_bar.set_description(f\"Epoch: {epoch} Max Accuracy: {max_acc:.4f}\")\n",
    "```\n",
    "\n",
    "好现在跑\n",
    "\n",
    "![](image-6.png)\n",
    "\n",
    "可以看到达到了 85，勉强复现了助教说的 86， 那么问题有可能是dropout=0.5 太大。\n",
    "\n",
    "现在关闭dropout，看看效果\n",
    "\n",
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=1 python main.py --model cnn --batch_size 64 --dropout 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48d9df0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
