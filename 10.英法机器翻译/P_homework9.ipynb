{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# 知识工程-作业10 英法中文翻译\n",
    "2024214500 叶璨铭\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## 代码与文档格式说明\n",
    "\n",
    "> 本文档使用Jupyter Notebook编写，遵循Diátaxis 系统 Notebook实践 https://nbdev.fast.ai/tutorials/best_practices.html，所以同时包括了实验文档和实验代码。\n",
    "\n",
    "> 本文档理论上支持多个格式，包括ipynb, docx, pdf 等。您在阅读本文档时，可以选择您喜欢的格式来进行阅读，建议您使用 Visual Studio Code (或者其他支持jupyter notebook的IDE, 但是VSCode阅读体验最佳) 打开 `ipynb`格式的文档来进行阅读。\n",
    "\n",
    "> 为了记录我们自己修改了哪些地方，使用git进行版本控制，这样可以清晰地看出我们基于助教的代码在哪些位置进行了修改，有些修改是实现了要求的作业功能，而有些代码是对原本代码进行了重构和优化。我将我在知识工程课程的代码，在作业截止DDL之后，开源到 https://github.com/2catycm/THU-Coursework-Knowledge-Engineering.git ，方便各位同学一起学习讨论。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "## 代码规范说明\n",
    "\n",
    "在我们实现函数过程中，函数的docstring应当遵循fastai规范而不是numpy规范，这样简洁清晰，不会Repeat yourself。相应的哲学和具体区别可以看 \n",
    "https://nbdev.fast.ai/tutorials/best_practices.html#keep-docstrings-short-elaborate-in-separate-cells\n",
    "\n",
    "\n",
    "为了让代码清晰规范，在作业开始前，使用 `ruff format`格式化助教老师给的代码; \n",
    "\n",
    "![alt text](image.png)\n",
    "\n",
    "\n",
    "很好，这次代码格式化没有报错。\n",
    "\n",
    "Pylance 似乎也没有明显问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431382e5",
   "metadata": {},
   "source": [
    "## 实验环境准备\n",
    "\n",
    "采用上次的作业专属环境，为了跑通最新方法，使用3.12 和 torch 2.7\n",
    "\n",
    "```bash\n",
    "conda create -n assignments python=3.12\n",
    "conda activate assignments\n",
    "pip install -r ../requirements.txt\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "pip install -U git+https://github.com/TorchRWKV/flash-linear-attention\n",
    "```\n",
    "\n",
    "本次作业似乎没有新的依赖，只是用到了 torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "## 原理回顾和课件复习\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "source": [
    "课上详细介绍了 概述、传统、统计、神经方法\n",
    "\n",
    "概述中，注意到“平行语料库”这个概念，平行语料库（Parallel Corpus）是指在两个或多个语言之间具有对齐关系的文本集合。每对对应的文本在不同语言中表达了相同或相似的意义，因而可以用于语言间的比较、翻译模型的训练、语言学研究以及其他自然语言处理任务。罗塞塔石碑就是典型例子，罗塞塔石碑是一块刻有相同内容但用三种不同书写系统（古埃及象形文字、埃及民用文和古希腊文）的石碑。正是因为这些文本内容一致，学者们才能利用已知语言（古希腊文）的信息，逐步破译不明的古埃及象形文字，揭开了古埃及语言和文化的神秘面纱。\n",
    "\n",
    "1947年，机器翻译认为是解读密码。1966年陷入低迷，1978年恢复。\n",
    "\n",
    "难点是语言表达有歧义、文化有差异、翻译和知识、常识有关、解不唯一、新词和专有名词。\n",
    "\n",
    "简单直接翻译方法直接替换已知的单词、短语、句子，然后调整顺序。\n",
    "\n",
    "基于规则的方法用规则描述语法，对句子进行词法分析（把连续的字符序列划分成独立的词或符号（即“词元”或“标记”））、句法分析（在词法分析的基础上，利用预先定义的语法规则构造句子的句法结构（如语法树），确定不同词汇之间的组合规则和结构关系。）、语义分析（不仅关注词语的基本含义，还要判断它们在上下文中的语境作用，识别歧义、隐含意义和语义角色）。生成译文的句子结构（两个语言表达顺序不同），然后选择词法。\n",
    "也叫作基于Transform的方法，这是独立分析两个语言的结构。缺点是语言写得不符合预定义的语法的时候处理不了。\n",
    "\n",
    "注意，基于规则的方法无需依赖双语平行语料。（？需要词典，词典不算吗）\n",
    "\n",
    "基于实例的方法，会类比已有的标准翻译实例，然后拼凑新的翻译。\n",
    "\n",
    "\n",
    "基于统计的翻译，使用噪声信道模型。从S翻译到T，认为是T经过噪声干扰变成了S。求 P(T|S)， \n",
    "可以求 P(S|T) 和 P(T) 后者直接统计词频。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b8f52e",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "\n",
    "助教已经帮我们preprocess好了数据，注意到有四个json文件。有两个是单词编码为id，词典对照。\n",
    "train和valid是 jsonl 的格式， 一行是一个 句子翻译到一个句子。\n",
    "\n",
    "![alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f1238c",
   "metadata": {},
   "source": [
    "## 补充完成`./metrics.py`中BLEU的计算\n",
    "\n",
    "首先了解一下BLEU的概念, 参考课件和 https://en.wikipedia.org/wiki/BLEU 。\n",
    "\n",
    "BLEU 全称 bilingual evaluation understudy，雙語替換評測，“Understudy”在这里指的是“替补演员”，在戏剧、表演等领域，指那些在正式演员因故无法出演时，能够随时顶替其角色的演员。\n",
    "\n",
    "想要评测 Quality/correspondence/accuracy。 wiki说是2001, 课件是2002， IBM发明。不考虑可理解性、语法正确性，只考虑与参考答案（有一组， a set of good quality reference translations）像不像。输出[0,1]。数据集=语料库 corpus，有多个翻译预测和多组翻译参考答案。\n",
    "\n",
    "\n",
    "首先需要指定 N-Gram 的 N，对于字符串，可以找到 其 N-Grams 的（不重复）集合。\n",
    "![alt text](image-2.png)\n",
    "\n",
    "\n",
    "然后定义出现次数C\n",
    "![alt text](image-3.png)\n",
    "\n",
    "S有M个预测答案，M组参考答案。\n",
    "![alt text](image-4.png)\n",
    "\n",
    "首先定义 Modified N-Gram Precision，既然是Precision，不是Recall，所以就是从预测答案来看\n",
    "\n",
    "在预测的答案中，每一个N-Gram出现了很多次，对于每一个N-Gram而言，想看看在标准答案里面出现多少次，如果比我少，那我不准，我做多了，可能凭空翻译了新东西。有一组标准答案，所以里面对我最好的那个（出现我的ngram最多的那个）和我比。\n",
    "![alt text](image-5.png)\n",
    "\n",
    "这个式子另一个角度看，是为了衡量，参考句子多少个n gram时候是在 候选句子中有的，有多少次。\n",
    "\n",
    "有了 Modified N-Gram Precision 之后，BLEU引入 Brevity penalty  简洁性惩罚（不是惩罚之后变简洁，而是简洁的被惩罚）。\n",
    "\n",
    "因为刚才的指标不恰当地（unduly）会奖励那种为了拿分全部N-Gram都说一遍（telegraphic）的模型。\n",
    "\n",
    "仔细看了看，我理解错了，惩罚的是有N-Gram，但是只说一遍，后面忘记说了的模型。\n",
    "\n",
    "\n",
    "![alt text](image-6.png)\n",
    "\n",
    "乍一看，\n",
    "r是 real 的长度（一组里面最接近c的那个），c是candidate的长度。\n",
    "\n",
    "如果c比r长就不惩罚了（我说的那个问题好像不是这里解决）\n",
    "\n",
    "实际上，\n",
    "需要注意BP是对整个语料库算的，不是对单个句子！是求了个和！整体进行惩罚！\n",
    "\n",
    "![alt text](image-7.png)\n",
    "\n",
    "![alt text](image-8.png)\n",
    "\n",
    "最终，BLEU 认为 很多 N Gram都重要，要加权算，所以枚举n=1到无穷，有wn分布来加权，得到\n",
    "\n",
    "![alt text](image-9.png)\n",
    "\n",
    "几何平均数是希望，模型不是只在一个N Gram上表现好，而是大部分都好。\n",
    "\n",
    "原本论文只考虑 n=1, 2, 3, 4, w = 1/4 。\n",
    "\n",
    "\n",
    " 批评BLEU的意见指出，没有分词边界的语言，或者英语使用不同的token方案，会导致BLEU分数差异很大，不可比较。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0345fc4",
   "metadata": {},
   "source": [
    "现在我们来实现，首先观察助教给的函数签名，顿时发现了问题\n",
    "\n",
    "candidate_corpus: List[List[str]]      # 形如 [[cand1_token1, cand1_token2, …], [cand2_…], …]\n",
    "references_corpus: List[List[str]]     # 同样是 [[ref1_token1, ref1_token2, …], [ref2_…], …]\n",
    "\n",
    "首先每一个 str 是 一个 token， 不是 句子哦， List[str] 是一个句子。\n",
    "\n",
    "第二，这里是一对一的，没有上面概念里面的 一个 candidate，多个 reference 的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a390e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(\n",
    "    candidate_corpus: List[List[str]],  # 候选翻译的token列表的列表。\n",
    "    references_corpus: List[\n",
    "        List[str]\n",
    "    ],  # 参考翻译的token列表的列表，数量应与候选一一对应。\n",
    "    max_n=4,  # 最大的ngram的数量，默认4。\n",
    "    weights: List[float] = [0.25]\n",
    "    * 4,  # 用于计算加权几何平均时的权重列表，长度应为max_n。\n",
    "    verbose: bool = True,\n",
    ") -> float:  # BLEU分数（0到1之间）。\n",
    "    \"\"\"\n",
    "    计算候选翻译语料库和参考翻译语料库之间的BLEU分数。\n",
    "    \"\"\"\n",
    "    assert len(candidate_corpus) == len(references_corpus), (\n",
    "        \"候选翻译和参考翻译的数量必须一致。\"\n",
    "    )\n",
    "    assert len(weights) == max_n, \"权重列表的长度必须等于最大的ngram数量。\"\n",
    "\n",
    "    total_clip_count = [0] * max_n\n",
    "    total_candidate_ngrams = [0] * max_n\n",
    "    total_candidate_length = 0\n",
    "    total_reference_length = 0\n",
    "\n",
    "    for candidate, references in zip(candidate_corpus, references_corpus):\n",
    "        candidate_ngrams = _compute_ngram_counter(candidate, max_n)\n",
    "        reference_ngrams = [_compute_ngram_counter(ref, max_n) for ref in references]\n",
    "        max_reference_ngrams = collections.Counter()\n",
    "        for ref_ngrams in reference_ngrams:\n",
    "            for ngram, count in ref_ngrams.items():\n",
    "                max_reference_ngrams[ngram] = max(max_reference_ngrams[ngram], count)\n",
    "\n",
    "        for n in range(1, max_n + 1):\n",
    "            for ngram, count in candidate_ngrams.items():\n",
    "                if len(ngram) == n:\n",
    "                    total_candidate_ngrams[n - 1] += count\n",
    "                    total_clip_count[n - 1] += min(count, max_reference_ngrams[ngram])\n",
    "\n",
    "        candidate_length = len(candidate)\n",
    "        total_candidate_length += candidate_length\n",
    "        reference_lengths = [len(ref) for ref in references]\n",
    "        closest_ref_length = min(\n",
    "            reference_lengths, key=lambda x: abs(x - candidate_length)\n",
    "        )\n",
    "        total_reference_length += closest_ref_length\n",
    "\n",
    "    precisions = []\n",
    "    for clip_count, candidate_ngrams in zip(total_clip_count, total_candidate_ngrams):\n",
    "        if candidate_ngrams == 0:\n",
    "            precisions.append(0)\n",
    "        else:\n",
    "            precisions.append(clip_count / candidate_ngrams)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Precisions: {precisions}\")\n",
    "        print(f\"Total candidate length: {total_candidate_length}\")\n",
    "        print(f\"Total reference length: {total_reference_length}\")\n",
    "\n",
    "    if total_candidate_length == 0:\n",
    "        return 0\n",
    "\n",
    "    brevity_penalty = (\n",
    "        1\n",
    "        if total_candidate_length >= total_reference_length\n",
    "        else math.exp(1 - total_reference_length / total_candidate_length)\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Brevity penalty: {brevity_penalty}\")\n",
    "\n",
    "    log_precisions = [math.log(p) if p > 0 else float(\"-inf\") for p in precisions]\n",
    "    bleu = brevity_penalty * math.exp(\n",
    "        sum(w * p for w, p in zip(weights, log_precisions))\n",
    "    )\n",
    "\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed71b8",
   "metadata": {},
   "source": [
    "简单测试一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4ce7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisions: [0.875, 0.6666666666666666, 0.25, 0.0]\n",
      "Total candidate length: 8\n",
      "Total reference length: 9\n",
      "Brevity penalty: 0.8824969025845955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metrics import bleu_score\n",
    "\n",
    "# 示例候选翻译语料库\n",
    "candidate_corpus = [[\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"], [\"hello\", \"world\"]]\n",
    "# 示例参考翻译语料库\n",
    "references_corpus = [\n",
    "    [[\"the\", \"cat\", \"is\", \"sitting\", \"on\", \"the\", \"mat\"]],\n",
    "    [[\"hello\", \"world\"]],\n",
    "]\n",
    "\n",
    "score = bleu_score(candidate_corpus, references_corpus)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf0786",
   "metadata": {},
   "source": [
    "可以发现，因为句子太短，没有 4-Gram! BLEU 分数为 0 的原因是 4-gram 的精确率为 0，导致其对数为负无穷（log(0) = -inf），最终加权平均后的指数部分为负无穷，使得整体结果为 0。这是符合数学定义的，并非代码错误。\n",
    "\n",
    "测试用例中，第一个候选翻译 [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"] 和参考翻译 [\"the\", \"cat\", \"is\", \"sitting\", \"on\", \"the\", \"mat\"] 的 4-gram 必然无法匹配（候选长度为 6，4-gram 数量为 3；参考长度为 7，4-gram 数量为 4），因此 4-gram 精确率为 0 是合理的。\n",
    "BLEU 分数的数学定义中，只要任意 n-gram 的精确率为 0，其对数会拉低整个指数项，导致结果趋近于 0。这是正常现象。\n",
    "\n",
    "我们可以让 max_n=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2fa7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisions: [0.875, 0.6666666666666666, 0.25]\n",
      "Total candidate length: 8\n",
      "Total reference length: 9\n",
      "Brevity penalty: 0.8824969025845955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.464513981711853"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = bleu_score(candidate_corpus, references_corpus, max_n=3, weights=[1 / 3] * 3)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134aeb30",
   "metadata": {},
   "source": [
    "## 阅读`model/transformer.py`并补充完成multihead attention\n",
    "\n",
    "拿到助教给我们的代码，首先注意到分为 context  和 attention两个部分。\n",
    "\n",
    "```python\n",
    "context, attention = None, None\n",
    "# TODO\n",
    "return context, attention\n",
    "```\n",
    "\n",
    "其实 context就是输出的hidden states, attention 分数是中间结果，可能要可视化吧。\n",
    "\n",
    "由于维度比较高，难以思考，所以我们决定用 某次作业助教用到的 einops 来尝试实现 这个 attention。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019fea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import einsum\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"实现Scaled Dot-Product Attention\"\"\"\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        q: torch.Tensor,\n",
    "        k: torch.Tensor,\n",
    "        v: torch.Tensor,  # [batch_size, num_heads, seq_len, hidden_size / num_heads]\n",
    "        mask: torch.Tensor  # [batch_size, 1, seq_len, seq_len]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        output:\n",
    "            - context: 输出值\n",
    "            - attention: 计算得到的注意力矩阵\n",
    "        \"\"\"\n",
    "        d_k = q.size(-1)\n",
    "        sqrt_d_k = torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "        # 计算点积，使用einops的einsum\n",
    "        \n",
    "        # b,h 独立，做乘法的是 i,j，\n",
    "        # d 维度会进行求和操作，因为它只在输入中出现，不在输出中出现（被reduce掉了）。\n",
    "        scores = einsum(q, k, 'b h i d, b h j d -> b h i j') / sqrt_d_k \n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9) # mask到的位置不能被 attention 注意到，本来是赋值为0，但是待会有softmax，应该给-inf。\n",
    "\n",
    "        attention = self.softmax(scores)\n",
    "        attention = self.dropout(attention)\n",
    "\n",
    "        # 计算context，使用einops的einsum\n",
    "        # b,h 独立，i， d乘法；对 j 求和\n",
    "        context = einsum(attention, v, 'b h i j, b h j d -> b h i d')\n",
    "        return context, attention\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b78dc",
   "metadata": {},
   "source": [
    "注意掩码约定为masks 的形状为 (batch, i, j)，i：代表 查询（Query）的位置（例如，序列中每个 token 作为查询时的索引）；j：代表 键（Key）的位置（例如，序列中每个 token 作为键时的索引）。\n",
    "掩码 masks[b, i, j] 表示：第 b 个批次中，查询位置 i 能否关注键位置 j（通常为 0 或 1，或用于缩放的权重）。\n",
    "\n",
    "decoder中，不允许 i 关注 >i 的 j， 所以 mask 是 下三角矩阵，i可以大于j，j不可以大于i。\n",
    "\n",
    "参考 torch 官网文档 https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
    "![alt text](image-10.png)\n",
    "\n",
    "我们的掩码约定和其一样。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41411db",
   "metadata": {},
   "source": [
    "我们可以简单测试一下我们的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "003efe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context shape: torch.Size([2, 4, 3, 8])\n",
      "Attention shape: torch.Size([2, 4, 3, 3])\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# 定义参数\n",
    "batch_size = 2\n",
    "num_heads = 4\n",
    "seq_len = 3\n",
    "hidden_size_per_head = 8\n",
    "dropout = 0.1\n",
    "\n",
    "# 创建模拟输入\n",
    "q = torch.randn(batch_size, num_heads, seq_len, hidden_size_per_head)\n",
    "k = torch.randn(batch_size, num_heads, seq_len, hidden_size_per_head)\n",
    "v = torch.randn(batch_size, num_heads, seq_len, hidden_size_per_head)\n",
    "mask = torch.tril(torch.ones(batch_size, 1, seq_len, seq_len))\n",
    "\n",
    "# 初始化模型\n",
    "attention_module = ScaledDotProductAttention(dropout)\n",
    "\n",
    "# 前向传播\n",
    "context, attention = attention_module(q, k, v, mask)\n",
    "\n",
    "print(f\"Context shape: {context.shape}\")\n",
    "print(f\"Attention shape: {attention.shape}\")\n",
    "print(\"Test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7870bd9",
   "metadata": {},
   "source": [
    "我们可以可视化一下 attention score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09462251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 使用seaborn绘制热力图\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(attention[0, 0], annot=True, cmap='viridis')\n",
    "plt.title('Tensor Heatmap')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb328e8",
   "metadata": {},
   "source": [
    "现在继续实现多头注意力\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b6471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads, dropout):\n",
    "        \"\"\"实现Multi-Head Attention\"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.linear_q = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear_k = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear_v = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.scaled_dot_product_attention = ScaledDotProductAttention(dropout)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        q: torch.Tensor,\n",
    "        k: torch.Tensor,\n",
    "        v: torch.Tensor,  # [batch_size, num_heads, seq_len, hidden_size / num_heads]\n",
    "        mask: torch.Tensor  # [batch_size, 1, seq_len, seq_len]\n",
    "    ):\n",
    "        residual = q\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        # 线性变换\n",
    "        q = self.linear_q(q)\n",
    "        k = self.linear_k(k)\n",
    "        v = self.linear_v(v)\n",
    "\n",
    "        # 分割成多个头\n",
    "        head_dim = self.hidden_size // self.num_heads\n",
    "        q = q.view(batch_size, -1, self.num_heads, head_dim).transpose(1, 2)\n",
    "        k = k.view(batch_size, -1, self.num_heads, head_dim).transpose(1, 2)\n",
    "        v = v.view(batch_size, -1, self.num_heads, head_dim).transpose(1, 2)\n",
    "\n",
    "        # 应用缩放点积注意力\n",
    "        context, attention = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        # 拼接多个头的输出\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.hidden_size)\n",
    "\n",
    "        # 通过线性层\n",
    "        output = self.linear(context)\n",
    "        output = self.dropout_layer(output)\n",
    "\n",
    "        # 残差连接和层归一化\n",
    "        output = self.layer_norm(output + residual)\n",
    "\n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66ccb44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 3, 8])\n",
      "Attention shape: torch.Size([2, 4, 3, 3])\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# 定义参数\n",
    "batch_size = 2\n",
    "seq_len = 3\n",
    "hidden_size = 8\n",
    "num_heads = 4\n",
    "dropout = 0.1\n",
    "\n",
    "# 创建模拟输入\n",
    "q = torch.randn(batch_size, seq_len, hidden_size)\n",
    "k = torch.randn(batch_size, seq_len, hidden_size)\n",
    "v = torch.randn(batch_size, seq_len, hidden_size)\n",
    "mask = torch.tril(torch.ones(batch_size, 1, seq_len, seq_len))\n",
    "\n",
    "# 初始化多头注意力模块\n",
    "multi_head_attention = MultiHeadAttention(hidden_size, num_heads, dropout)\n",
    "\n",
    "# 前向传播\n",
    "output, attention = multi_head_attention(q, k, v, mask)\n",
    "\n",
    "# 打印输出形状\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Attention shape: {attention.shape}\")\n",
    "print(\"Test passed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
