{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# 知识工程-作业9 基于知识图谱的问答系统\n",
    "2024214500 叶璨铭\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## 代码与文档格式说明\n",
    "\n",
    "> 本文档使用Jupyter Notebook编写，遵循Diátaxis 系统 Notebook实践 https://nbdev.fast.ai/tutorials/best_practices.html，所以同时包括了实验文档和实验代码。\n",
    "\n",
    "> 本文档理论上支持多个格式，包括ipynb, docx, pdf 等。您在阅读本文档时，可以选择您喜欢的格式来进行阅读，建议您使用 Visual Studio Code (或者其他支持jupyter notebook的IDE, 但是VSCode阅读体验最佳) 打开 `ipynb`格式的文档来进行阅读。\n",
    "\n",
    "> 为了记录我们自己修改了哪些地方，使用git进行版本控制，这样可以清晰地看出我们基于助教的代码在哪些位置进行了修改，有些修改是实现了要求的作业功能，而有些代码是对原本代码进行了重构和优化。我将我在知识工程课程的代码，在作业截止DDL之后，开源到 https://github.com/2catycm/THU-Coursework-Knowledge-Engineering.git ，方便各位同学一起学习讨论。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "## 代码规范说明\n",
    "\n",
    "在我们实现函数过程中，函数的docstring应当遵循fastai规范而不是numpy规范，这样简洁清晰，不会Repeat yourself。相应的哲学和具体区别可以看 \n",
    "https://nbdev.fast.ai/tutorials/best_practices.html#keep-docstrings-short-elaborate-in-separate-cells\n",
    "\n",
    "\n",
    "为了让代码清晰规范，在作业开始前，使用 `ruff format`格式化助教老师给的代码; \n",
    "\n",
    "![alt text](image.png)\n",
    "\n",
    "\n",
    "很好，这次代码格式化没有报错。\n",
    "\n",
    "Pylance 似乎也没有明显问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431382e5",
   "metadata": {},
   "source": [
    "## 实验环境准备\n",
    "\n",
    "采用上次的作业专属环境，为了跑通最新方法，使用3.12 和 torch 2.6\n",
    "\n",
    "```bash\n",
    "conda create -n assignments python=3.12\n",
    "conda activate assignments\n",
    "pip install -r ../requirements.txt\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "pip install -U git+https://github.com/TorchRWKV/flash-linear-attention\n",
    "```\n",
    "\n",
    "本次作业似乎没有新的依赖，只是用到了 transformers\n",
    "\n",
    "```python\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "## 原理回顾和课件复习\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "source": [
    "课上详细介绍了 Knowledge-based Question Answering\n",
    "\n",
    "首先区分了一下属性和关系，属性是 实体, 属性类型, 字符串； 关系是 实体，关系类型，实体。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "## 1.1 基于知识图谱的问答系统\n",
    "\n",
    "根据助教老师的要求，我们有四步要做\n",
    "\n",
    "1. 使用 Python 解析 zhishime.json 文件，创建知识图谱\n",
    "2. 实现头实体检索模块（使用正向最大匹配或命名实体识别）\n",
    "3. 使用预训练模型计算问题与关系的相似度\n",
    "4. 提取答案并评估准确性\n",
    "\n",
    "\n",
    "### 1. 使用 python 解析 zhishime.json 文件，并将解析出的 dict 保存为文件\n",
    "\n",
    "注意到 zhishime 实际上是一个 jsonl文件，一行是一个json，每一行是\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"_id\": {\"$oid\": \"5a4a0579b63209a91d0c41c7\"},\n",
    "    \"head\": \"1987大悬案\",\n",
    "    \"relation\": \"监制\",\n",
    "    \"tail\": \"狄诺迪洛伦提斯\\u003cbr/\\u003eRichardRoth\\u003cbr/\\u003e柏尼·威廉斯\",\n",
    "}\n",
    "```\n",
    "\n",
    "这样的格式, 也就是说有 _id, head, relation 和 tail \n",
    "\n",
    "这是知识图谱的典型的三元组。\n",
    "\n",
    "老师已经给了我们 preprocess.py 的初步实现。\n",
    "\n",
    "```python\n",
    "kg = {\n",
    "        \"head2id\": head2id,\n",
    "        \"tail2id\": tail2id,\n",
    "        \"relation2id\": relation2id,\n",
    "        \"relation_triplets\": relation_triplets,\n",
    "    }\n",
    "```\n",
    "\n",
    "这个函数的目标是为了得到 head tail 的id，其实和没处理差不多。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac29f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess():\n",
    "    \"\"\"预处理知识图谱数据，构建实体映射和三元组索引\"\"\"\n",
    "    # 初始化数据结构\n",
    "    kg = {\n",
    "        \"head2id\": {},     # 头实体到ID的映射\n",
    "        \"tail2id\": {},     # 尾实体到ID的映射  \n",
    "        \"relation2id\": {}, # 关系到ID的映射\n",
    "        \"relation_triplets\": []  # 存储(hid, rid, tid)形式的三元组\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # 确保输出目录存在\n",
    "        os.makedirs(\"./processed\", exist_ok=True)\n",
    "        \n",
    "        # 读取原始JSONL文件（注意：使用..表示上级目录）\n",
    "        with open(\"../zhishime.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            # 逐行解析JSON对象（适用于JSON Lines格式）\n",
    "            raw_relation_data = [json.loads(line) for line in f]\n",
    "            \n",
    "            # 等价写法（更易理解）：\n",
    "            # raw_relation_data = []\n",
    "            # for line in f:\n",
    "            #     data = json.loads(line)\n",
    "            #     raw_relation_data.append(data)\n",
    "\n",
    "        # 遍历每个三元组进行索引构建\n",
    "        bar = tqdm(raw_relation_data)\n",
    "        for item in bar:\n",
    "            head = item[\"head\"]\n",
    "            relation = item[\"relation\"]\n",
    "            \n",
    "            # 处理包含换行符的尾实体（示例数据中的<br/>分隔符）\n",
    "            tail = item[\"tail\"].replace(\"\\u003cbr/\\u003e\", \", \")  # 将HTML换行符转换为逗号分隔\n",
    "            \n",
    "            # 构建实体ID映射（自动递增分配ID）\n",
    "            # head2id.setdefault等效写法，但更推荐当前写法\n",
    "            if head not in kg[\"head2id\"]:\n",
    "                kg[\"head2id\"][head] = len(kg[\"head2id\"])\n",
    "                \n",
    "            if tail not in kg[\"tail2id\"]:\n",
    "                kg[\"tail2id\"][tail] = len(kg[\"tail2id\"])\n",
    "                \n",
    "            if relation not in kg[\"relation2id\"]:\n",
    "                kg[\"relation2id\"][relation] = len(kg[\"relation2id\"])\n",
    "            \n",
    "            # 构建三元组索引\n",
    "            hid = kg[\"head2id\"][head]\n",
    "            rid = kg[\"relation2id\"][relation]\n",
    "            tid = kg[\"tail2id\"][tail]\n",
    "            kg[\"relation_triplets\"].append((hid, rid, tid))\n",
    "\n",
    "        # 打印统计信息\n",
    "        print(f\"[统计] 头实体数: {len(kg['head2id'])} | 尾实体数: {len(kg['tail2id'])} | 关系类型数: {len(kg['relation2id'])}\")\n",
    "        print(f\"[统计] 总三元组数: {len(kg['relation_triplets'])}\")\n",
    "\n",
    "        # 保存处理结果\n",
    "        with open(\"./processed/kg.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json.dump(kg, json_file, \n",
    "                     ensure_ascii=False,  # 保留非ASCII字符原文\n",
    "                     indent=4)           # 美化格式便于查看\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"错误：未找到原始数据文件，请检查路径是否正确\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON解析错误：第{e.lineno}行数据格式异常，错误详情：{e.msg}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb76c6c",
   "metadata": {},
   "source": [
    "我们稍微重构了下，让整个功能更加稳定。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0969250",
   "metadata": {},
   "source": [
    "![alt text](image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc00fb",
   "metadata": {},
   "source": [
    "### 2. 实现头实体检索模块（使用正向最大匹配或命名实体识别）\n",
    "\n",
    "在实现这个函数之前，我们需要明确一个问题，\n",
    "- what：到底什么是头实体？\n",
    "- 在一个question里面，头实体应该是一个还是多个？\n",
    "\n",
    "事实上，这个和对问题的模板预设有关，这次实验我们假设问题类似于 “{HEAD} 的 {RELATION}?” ， 回答是 “{TAIL}”， 所以认为问题中就只有一个实体。例如：\"周杰伦的出生日期是什么？\" → 头实体是\"周杰伦\"。\n",
    "\n",
    "实际上问题中可能包含多个实体，但通常只有一个是头实体\n",
    "\n",
    "例如：\"周杰伦和林俊杰谁的粉丝多？\" → 这种情况复杂一些，可能需要查询多个头实体。\n",
    "\n",
    "\n",
    "刚才我们定义了 \"head2id\": {},     # 头实体到ID的映射\n",
    "\n",
    "所以，我们只需要做一个“多字符串(模式)匹配\", 找到 question 字符串中的那一个实体就好。\n",
    "\n",
    "所谓 正向最大匹配法，就是在问题字符串中，尝试匹配知识图谱中最长的实体名称，优先匹配最长的实体名称，因为这样更可能是完整的实体。 那么相应的逻辑就很简单了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d875695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_head_entity(kg: dict, question: str) -> str:\n",
    "    \"\"\"基于正向最大匹配的头实体识别\n",
    "    Args:\n",
    "        kg: 知识图谱字典，包含head2id等字段\n",
    "        question: 待查询的问题文本\n",
    "    Returns:\n",
    "        匹配成功的头实体字符串，未找到返回None\n",
    "    \"\"\"\n",
    "    # 获取所有可能的头实体\n",
    "    all_heads = list(kg['head2id'].keys())\n",
    "    \n",
    "    # 对头实体按长度排序，优先匹配长的实体\n",
    "    all_heads.sort(key=len, reverse=True)\n",
    "    \n",
    "    # 遍历所有头实体，检查是否在问题中出现\n",
    "    for head in all_heads:\n",
    "        if head in question:\n",
    "            return head\n",
    "    \n",
    "    # 如果没有找到匹配的头实体\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13367106",
   "metadata": {},
   "source": [
    "为了提高处理速度，我们使用缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c37f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_heads = None\n",
    "\n",
    "def search_head_entity(kg: dict, question: str) -> str:\n",
    "    \"\"\"基于正向最大匹配的头实体识别\n",
    "    Args:\n",
    "        kg: 知识图谱字典，包含head2id等字段\n",
    "        question: 待查询的问题文本\n",
    "    Returns:\n",
    "        匹配成功的头实体字符串，未找到返回None\n",
    "    \"\"\"\n",
    "    # 获取所有可能的头实体\n",
    "    global sorted_heads\n",
    "    if sorted_heads is None:\n",
    "        all_heads = list(kg['head2id'].keys())\n",
    "        \n",
    "        # 对头实体按长度排序，优先匹配长的实体\n",
    "        sorted_heads = sorted(all_heads, key=len, reverse=True)\n",
    "    \n",
    "    # 遍历所有头实体，检查是否在问题中出现\n",
    "    for head in sorted_heads:\n",
    "        if head in question:\n",
    "            return head\n",
    "    \n",
    "    # 如果没有找到匹配的头实体\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d9ba97",
   "metadata": {},
   "source": [
    "注意到后面的代码是这样的\n",
    "\n",
    "head = search_head_entity(kg, question)\n",
    "        if head is None:\n",
    "\n",
    "为了不让类型有问题（不想用optional），我觉得应该改成\n",
    "if head==\"\":"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4da9502",
   "metadata": {},
   "source": [
    "### 3. 使用预训练模型计算问题与关系的相似度\n",
    "\n",
    "检查 main.py 代码，发现原本代码这里写错了\n",
    "\n",
    "relations = list(kg[head].keys())\n",
    "\n",
    "我们在kg中根本没有存储从 head 映射到 关系本身的信息！\n",
    "\n",
    "所以我们需要重新修改 preprocess.py 把这个信息假如进去才对。\n",
    "\n",
    "刚才处理json的时候搞了半天id其实是无用功，根本不需要id，核心问题是 一个head有多少个相关的relation。\n",
    "\n",
    "\n",
    "\n",
    "同理，这段代码也不对\n",
    "\n",
    "answer = kg[head][max_relation]\n",
    "\n",
    "这里要解决的核心问题是，给定一个head和一个relation，找到对应的tail的集合。\n",
    "\n",
    "我们首先加上代码\n",
    "\n",
    "```python\n",
    "# 构建头实体到关系的映射\n",
    "if head not in kg[\"head2relations\"]:\n",
    "    kg[\"head2relations\"][head] = set()\n",
    "kg[\"head2relations\"][head].add(relation)\n",
    "\n",
    "# 构建头实体到关系和答案的映射\n",
    "if (head, relation) not in kg[\"head_relations2answers\"]:\n",
    "    kg[\"head_relations2answers\"][(head, relation)] = \"\"\n",
    "kg[\"head_relations2answers\"][(head, relation)] += f\"{tail}, \"\n",
    "```\n",
    "\n",
    "重新运行 python preprocess.py\n",
    "\n",
    "现在可以看到\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c47068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['head2id', 'tail2id', 'relation2id', 'relation_triplets'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"data/processed/kg.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    kg = json.load(f)\n",
    "kg.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f241050",
   "metadata": {},
   "source": [
    "在main中使用 \n",
    "```python\n",
    "        relations = list(kg[\"head2relations\"][head])\n",
    "        ...\n",
    "        answer = kg[\"head_relations2answers\"][(head, max_relation)]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
