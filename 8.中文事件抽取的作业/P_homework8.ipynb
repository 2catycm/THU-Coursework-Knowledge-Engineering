{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# 知识工程-作业8 中文事件抽取\n",
    "2024214500 叶璨铭\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## 代码与文档格式说明\n",
    "\n",
    "> 本文档使用Jupyter Notebook编写，遵循Diátaxis 系统 Notebook实践 https://nbdev.fast.ai/tutorials/best_practices.html，所以同时包括了实验文档和实验代码。\n",
    "\n",
    "> 本文档理论上支持多个格式，包括ipynb, docx, pdf 等。您在阅读本文档时，可以选择您喜欢的格式来进行阅读，建议您使用 Visual Studio Code (或者其他支持jupyter notebook的IDE, 但是VSCode阅读体验最佳) 打开 `ipynb`格式的文档来进行阅读。\n",
    "\n",
    "> 为了记录我们自己修改了哪些地方，使用git进行版本控制，这样可以清晰地看出我们基于助教的代码在哪些位置进行了修改，有些修改是实现了要求的作业功能，而有些代码是对原本代码进行了重构和优化。我将我在知识工程课程的代码，在作业截止DDL之后，开源到 https://github.com/2catycm/THU-Coursework-Knowledge-Engineering.git ，方便各位同学一起学习讨论。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "## 代码规范说明\n",
    "\n",
    "在我们实现函数过程中，函数的docstring应当遵循fastai规范而不是numpy规范，这样简洁清晰，不会Repeat yourself。相应的哲学和具体区别可以看 \n",
    "https://nbdev.fast.ai/tutorials/best_practices.html#keep-docstrings-short-elaborate-in-separate-cells\n",
    "\n",
    "\n",
    "为了让代码清晰规范，在作业开始前，使用 `ruff format`格式化助教老师给的代码; \n",
    "\n",
    "![alt text](image.png)\n",
    "\n",
    "\n",
    "哇！我们当场就检查出了代码错误！不只是格式化问题了，看看 metrics/m2scorer/Tokenizer.py:177:15 和 metrics/m2scorer/token_offsets.py:43:15 是怎么回事\n",
    "\n",
    "![alt text](image-2.png)\n",
    "\n",
    "![alt text](image-1.png)\n",
    "\n",
    "\n",
    "原来是 m2scorer 太老了，居然用了 Python2 的语法！我们简单修改为 `print(\"\")` 语法就可以了。\n",
    "不过语句有点多啊，我们一个个改有点不够优雅。\n",
    "\n",
    "Python官方有工具，\n",
    "```bash\n",
    "2to3 -w .\n",
    "```\n",
    "\n",
    "![alt text](image-3.png)\n",
    "\n",
    "改了特别多东西\n",
    "\n",
    "![alt text](image-4.png)\n",
    "\n",
    "终于勉强看起来正常了，不过细看代码还是有很多不正常的地方，看来学长只是想让我们参考代码，这个应该是难以跑通的。\n",
    "\n",
    "\n",
    "\n",
    "同时注意到VSCode-Pylance插件的报错\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431382e5",
   "metadata": {},
   "source": [
    "## 实验环境准备\n",
    "\n",
    "\n",
    "上次作业结束的时候，我们注意到我们想要尝试的最新方法只能支持3.12，PyTorch2.4也不够新，所以我们这次作业重新创建一个作业专属3.12环境。\n",
    "\n",
    "先装小依赖包, 然后安装最新pytorch\n",
    "\n",
    "```bash\n",
    "conda create -n assignments python=3.12\n",
    "conda activate assignments\n",
    "pip install -r ../requirements.txt\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "```\n",
    "\n",
    "注意到\n",
    "\n",
    "```python\n",
    "from elmoformanylangs import Embedder, logger\n",
    "import einops\n",
    "import jieba\n",
    "```\n",
    "\n",
    "参考 https://github.com/HIT-SCIR/ELMoForManyLangs， 安装\n",
    "\n",
    "```bash\n",
    "git submodule add https://github.com/HIT-SCIR/ELMoForManyLangs\n",
    "cd ELMoForManyLangs\n",
    "pip install -e .\n",
    "```\n",
    "PyTorch版本没有冲突，不用被乱装一通，太棒了。\n",
    "\n",
    "安装一下上次没有探究完的 RWKV \n",
    "```bash\n",
    "pip install -U git+https://github.com/TorchRWKV/flash-linear-attention\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "## 原理回顾和课件复习\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "source": [
    "课上详细介绍了语法纠正任务的一些基本特点和难点，先介绍了规则模型和分类模型，然后开始介绍翻译任务用于语法纠正和噪声信道模型，然后详细介绍了 Seq2seq 的发展历程，最后提及了一下大模型方法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "\n",
    "download.sh 的清华网盘链接过期了，还好学长给的压缩包已经处理好了数据 NLPCC 2018 Task 2，已经有“./data/processed/”\n",
    "\n",
    "```python\n",
    "train_dataset = GECDataset(\n",
    "    \"./data/processed/seg.train\", vocab_dict=vocab_dict, max_length=200\n",
    ")\n",
    "test_dataset = GECDataset(\n",
    "    \"./data/processed/seg.txt\", vocab_dict=vocab_dict, max_length=200\n",
    ")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af00a63",
   "metadata": {},
   "source": [
    "## 预训练模型下载\n",
    "\n",
    "根据main.py, 首先我们需要下载  \"zhs.model\"\n",
    "```python\n",
    "elmo_model = Embedder(\"zhs.model\", batch_size=16)\n",
    "vocab_dict = load_vocab_dict(\"./zhs.model/word.dic\")\n",
    "```\n",
    "\n",
    "根据 https://github.com/HIT-SCIR/ELMoForManyLangs\n",
    "有两个链接都是下载中文模型的，特别强调后面的是简体中文。\n",
    "```bash\n",
    "wget http://vectors.nlpl.eu/repository/11/179.zip\n",
    "wget http://39.96.43.154/zhs.model.tar.bz2\n",
    "```\n",
    "后者链接失效了无法连接上！\n",
    "\n",
    "只好下载前面这个的 179.zip, 然后把里面的内容移动进去\n",
    "\n",
    "```bash\n",
    "unzip 179.zip\n",
    "md zhs.model\n",
    "mv char.dic config.json encoder.pkl meta.json README token_embedder.pkl word.dic zhs.model\n",
    "rm 179.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59636d0f",
   "metadata": {},
   "source": [
    "## 评价指标 Max Match 实现\n",
    "\n",
    "Max Match （因为有两个M 又叫作 M2 ）是由 NUS 的研究者在这篇2012 ACL 论文 https://aclanthology.org/N12-1067.pdf “Better Evaluation for Grammatical Error Correction” 提出的。\n",
    "\n",
    "老师的课件指出这是应用最广泛的指标之一。\n",
    "\n",
    "![alt text](image-5.png)\n",
    "\n",
    "\n",
    "MaxMatch (M²) 首先第一个思路是不再直接比较生成句子和参考句子的相似度，而是比较系统所做的“编辑操作” (edits) 与人类标注者提供的“标准编辑操作”的匹配程度，也就是课件中说的ei和gi。\n",
    "\n",
    "核心思想是“Max”，可以假设我们有多个标准答案，对于每一个人工标注的参考答案（即一个正确的句子版本），通过比较该参考答案和原始错误句子，找出从错误句子到这个特定正确版本所需的标准编辑操作。对于系统生成的句子所对应的一组编辑操作，M² 会尝试将其与每一个参考答案所对应的标准编辑操作集进行比较。\n",
    "\n",
    "它会计算系统编辑集与每一个标准编辑集之间的匹配程度（通常是计算重叠的编辑数量）。\n",
    "然后，它会选择那个能与系统编辑集产生最大匹配度（即最多重叠编辑）的参考答案。\n",
    "重要的是， M² 认为，只要系统做出的编辑与 任意一个 正确的参考答案中的编辑相匹配，这个编辑就是有效的。这就是“MaxMatch”的含义——在所有可能的标准答案中，找到对系统最有利（匹配度最高）的那一个来进行评估。\n",
    "\n",
    "M² 的主要目的是解决GEC评估中的模糊性问题：同一个错误修正问题可能有多种编辑操作序列导致相同的结果句子，而不同系统可能通过不同的编辑路径达到相同输出。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5fd9d0",
   "metadata": {},
   "source": [
    "那么具体要怎么实现呢？经过我的初步调查，助教建议的第一个参考代码 https://github.com/shibing624/pycorrector 虽然看起来集成了很多方法，但是 max match 指标似乎没有（或者不叫这个名字），评测的代码是 “https://github.com/shibing624/pycorrector/blob/master/pycorrector/utils/evaluate_utils.py” 但是我还没有看懂，这里面引入了\"SIGHAN\", \"句级评估结果\", \"设定需要纠错为正样本，无需纠错为负样本\" 这些概念，好像用了对比学习，但是没有直接说是用 Max Match。\n",
    "\n",
    "助教给我们的第二个代码就是 M² 的官方代码，也就是刚才我费了半天劲升级为 Python3 的代码。根据助教给的提示，我们可以直接外部调用其功能用来评估。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def maxmatch_metric(prediction_file: str # a file containing predicted output\n",
    "                    , label_file: str # a file containig groundtruth output\n",
    "                    ) -> Any:\n",
    "    \"\"\"\n",
    "    calculate maxmatch metrics\n",
    "\n",
    "    File content example\n",
    "    # prediction file\n",
    "    ```\n",
    "    冬 阴功 是 泰国 最 著名 的 菜 之一 ， 它 虽然 不 是 很 豪华 ， 但 它 的 味 确实 让 人 上瘾 ， 做法 也 不 难 、 不 复杂 。\n",
    "    首先 ， 我们 得 准备 : 大 虾六 到 九 只 、 盐 一 茶匙 、 已 搾 好 的 柠檬汁 三 汤匙 、 泰国 柠檬 叶三叶 、 柠檬 香草 一 根 、 鱼酱 两 汤匙 、 辣椒 6 粒 ， 纯净 水 4量杯 、 香菜 半量杯 和 草菇 10 个 。\n",
    "    ```\n",
    "    # label_file\n",
    "    ```\n",
    "    S 冬 阴功 是 泰国 最 著名 的 菜 之一 ， 它 虽然 不 是 很 豪华 ， 但 它 的 味 确实 让 人 上瘾 ， 做法 也 不 难 、 不 复杂 。\n",
    "    A 9 11|||W|||虽然 它|||REQUIRED|||-NONE-|||0\n",
    "\n",
    "    S 首先 ， 我们 得 准备 : 大 虾六 到 九 只 、 盐 一 茶匙 、 已 搾 好 的 柠檬汁 三 汤匙 、 泰国 柠檬 叶三叶 、 柠檬 香草 一 根 、 鱼酱 两 汤匙 、 辣椒 6 粒 ， 纯净 水 4量杯 、 香菜 半量杯 和 草菇 10 个 。\n",
    "    A 17 18|||S|||榨|||REQUIRED|||-NONE-|||0\n",
    "    A 38 39|||S|||六|||REQUIRED|||-NONE-|||0\n",
    "    A 43 44|||S|||四 量杯|||REQUIRED|||-NONE-|||0\n",
    "    A 49 50|||S|||十|||REQUIRED|||-NONE-|||0\n",
    "    ```\n",
    "    \"\"\"\n",
    "    subprocess.check_call(\n",
    "        [\"python\", \"metrics/m2scorer/m2scorer.py\", prediction_file, label_file]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a22d676",
   "metadata": {},
   "source": [
    "为此，我特意把助教注释里面的文件内容拿了出来进行测试，看看是否评测正确。\n",
    "\n",
    "![alt text](image-6.png)\n",
    "\n",
    "确实得是0， prediction_file 没有改错，这个是啥都不干的语法修正器。\n",
    "\n",
    "然后我按照grond truth的要求，让LLM遵循ground truth的命令更正语法，得到 prediction_file2\n",
    "\n",
    "![alt text](image-7.png)\n",
    "\n",
    "没想到居然不是完全对，precision差一个，意思是我们不小心多改了一个什么东西。\n",
    "\n",
    "仔细检查了半天，发现原来是助教给我们的Python 注释有问题，冬阴功分词给合起来了，我们修改一下 Python 注释以及 predicition_file_correct.txt 就行。\n",
    "\n",
    "![alt text](image-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa33c011",
   "metadata": {},
   "source": [
    "我们还可以写正则表达式提取一下这三个数值出来，这样返回的时候更好处理\n",
    "\n",
    "![alt text](image-9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f67843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxmatch_metric(prediction_file: str # a file containing predicted output\n",
    "                    , label_file: str # a file containig groundtruth output\n",
    "                    , verbose:bool = True\n",
    "                    ) -> Any:\n",
    "    \"\"\"\n",
    "    calculate maxmatch metrics\n",
    "\n",
    "    File content example\n",
    "    # prediction file\n",
    "    ```\n",
    "    冬 阴功 是 泰国 最 著名 的 菜 之一 ， 它 虽然 不 是 很 豪华 ， 但 它 的 味 确实 让 人 上瘾 ， 做法 也 不 难 、 不 复杂 。\n",
    "    首先 ， 我们 得 准备 : 大 虾六 到 九 只 、 盐 一 茶匙 、 已 搾 好 的 柠檬汁 三 汤匙 、 泰国 柠檬 叶三叶 、 柠檬 香草 一 根 、 鱼酱 两 汤匙 、 辣椒 6 粒 ， 纯净 水 4量杯 、 香菜 半量杯 和 草菇 10 个 。\n",
    "    ```\n",
    "    # label_file\n",
    "    ```\n",
    "    S 冬 阴功 是 泰国 最 著名 的 菜 之一 ， 它 虽然 不 是 很 豪华 ， 但 它 的 味 确实 让 人 上瘾 ， 做法 也 不 难 、 不 复杂 。\n",
    "    A 9 11|||W|||虽然 它|||REQUIRED|||-NONE-|||0\n",
    "\n",
    "    S 首先 ， 我们 得 准备 : 大 虾六 到 九 只 、 盐 一 茶匙 、 已 搾 好 的 柠檬汁 三 汤匙 、 泰国 柠檬 叶三叶 、 柠檬 香草 一 根 、 鱼酱 两 汤匙 、 辣椒 6 粒 ， 纯净 水 4量杯 、 香菜 半量杯 和 草菇 10 个 。\n",
    "    A 17 18|||S|||榨|||REQUIRED|||-NONE-|||0\n",
    "    A 38 39|||S|||六|||REQUIRED|||-NONE-|||0\n",
    "    A 43 44|||S|||四 量杯|||REQUIRED|||-NONE-|||0\n",
    "    A 49 50|||S|||十|||REQUIRED|||-NONE-|||0\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # subprocess.check_call(\n",
    "    #     [\"python\", \"metrics/m2scorer/m2scorer.py\", prediction_file, label_file]\n",
    "    # )\n",
    "    # 执行命令并捕获输出\n",
    "    result = subprocess.check_output(\n",
    "        [\"python\", \"metrics/m2scorer/m2scorer.py\", prediction_file, label_file],\n",
    "        text=True  # 直接获取文本输出，无需解码\n",
    "    )\n",
    "\n",
    "    # 打印原始输出\n",
    "    if verbose:\n",
    "        print(\"m2scorer评测中:\")\n",
    "        print(result)\n",
    "\n",
    "    # 使用正则表达式提取指标\n",
    "    metrics = {}\n",
    "    metrics_pattern = re.compile(r'(Precision|Recall|F0\\.5)\\s*:\\s*([\\d\\.]+)')\n",
    "    matches = metrics_pattern.findall(result)\n",
    "    \n",
    "    # 将匹配的结果转换为字典\n",
    "    for key, value in matches:\n",
    "        metrics[key] = float(value)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085bbcf2",
   "metadata": {},
   "source": [
    "当然这样会被底层代码限制住，只能获得4位小数，虽然对我们这次实验够用了，但是为了避免后人再被这个m2scorer坑住，我们决定把里面的代码改造一些出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440eb5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "this_file = Path(__file__).resolve()\n",
    "this_directory = this_file.parent\n",
    "import sys\n",
    "sys.path.append((this_directory/\"m2scorer\").as_posix())\n",
    "\n",
    "import levenshtein as levenshtein\n",
    "from util import paragraphs\n",
    "from util import smart_open\n",
    "from typing import Any\n",
    "\n",
    "def load_annotation(gold_file):\n",
    "    source_sentences = []\n",
    "    gold_edits = []\n",
    "    fgold = smart_open(gold_file, \"r\")\n",
    "    puffer = fgold.read()\n",
    "    fgold.close()\n",
    "    # puffer = puffer.decode('utf8')\n",
    "    for item in paragraphs(puffer.splitlines(True)):\n",
    "        item = item.splitlines(False)\n",
    "        sentence = [line[2:].strip() for line in item if line.startswith(\"S \")]\n",
    "        assert sentence != []\n",
    "        annotations = {}\n",
    "        for line in item[1:]:\n",
    "            if line.startswith(\"I \") or line.startswith(\"S \"):\n",
    "                continue\n",
    "            assert line.startswith(\"A \")\n",
    "            line = line[2:]\n",
    "            fields = line.split(\"|||\")\n",
    "            start_offset = int(fields[0].split()[0])\n",
    "            end_offset = int(fields[0].split()[1])\n",
    "            etype = fields[1]\n",
    "            if etype == \"noop\":\n",
    "                start_offset = -1\n",
    "                end_offset = -1\n",
    "            corrections = [\n",
    "                c.strip() if c != \"-NONE-\" else \"\" for c in fields[2].split(\"||\")\n",
    "            ]\n",
    "            # NOTE: start and end are *token* offsets\n",
    "            original = \" \".join(\" \".join(sentence).split()[start_offset:end_offset])\n",
    "            annotator = int(fields[5])\n",
    "            if annotator not in list(annotations.keys()):\n",
    "                annotations[annotator] = []\n",
    "            annotations[annotator].append(\n",
    "                (start_offset, end_offset, original, corrections)\n",
    "            )\n",
    "        tok_offset = 0\n",
    "        for this_sentence in sentence:\n",
    "            tok_offset += len(this_sentence.split())\n",
    "            source_sentences.append(this_sentence)\n",
    "            this_edits = {}\n",
    "            for annotator, annotation in annotations.items():\n",
    "                this_edits[annotator] = [\n",
    "                    edit\n",
    "                    for edit in annotation\n",
    "                    if edit[0] <= tok_offset\n",
    "                    and edit[1] <= tok_offset\n",
    "                    and edit[0] >= 0\n",
    "                    and edit[1] >= 0\n",
    "                ]\n",
    "            if len(this_edits) == 0:\n",
    "                this_edits[0] = []\n",
    "            gold_edits.append(this_edits)\n",
    "    return (source_sentences, gold_edits)\n",
    "\n",
    "\n",
    "def maxmatch_metric(prediction_file: str # a file containing predicted output\n",
    "                    , label_file: str # a file containig groundtruth output\n",
    "                    , verbose:bool = True\n",
    "                    ) -> Any:\n",
    "    \"\"\"\n",
    "    calculate maxmatch metrics\n",
    "\n",
    "    File content example\n",
    "    # prediction file\n",
    "    ```\n",
    "    冬 阴功 是 泰国 最 著名 的 菜 之一 ， 它 虽然 不 是 很 豪华 ， 但 它 的 味 确实 让 人 上瘾 ， 做法 也 不 难 、 不 复杂 。\n",
    "    首先 ， 我们 得 准备 : 大 虾六 到 九 只 、 盐 一 茶匙 、 已 搾 好 的 柠檬汁 三 汤匙 、 泰国 柠檬 叶三叶 、 柠檬 香草 一 根 、 鱼酱 两 汤匙 、 辣椒 6 粒 ， 纯净 水 4量杯 、 香菜 半量杯 和 草菇 10 个 。\n",
    "    ```\n",
    "    # label_file\n",
    "    ```\n",
    "    S 冬 阴功 是 泰国 最 著名 的 菜 之一 ， 它 虽然 不 是 很 豪华 ， 但 它 的 味 确实 让 人 上瘾 ， 做法 也 不 难 、 不 复杂 。\n",
    "    A 9 11|||W|||虽然 它|||REQUIRED|||-NONE-|||0\n",
    "\n",
    "    S 首先 ， 我们 得 准备 : 大 虾六 到 九 只 、 盐 一 茶匙 、 已 搾 好 的 柠檬汁 三 汤匙 、 泰国 柠檬 叶三叶 、 柠檬 香草 一 根 、 鱼酱 两 汤匙 、 辣椒 6 粒 ， 纯净 水 4量杯 、 香菜 半量杯 和 草菇 10 个 。\n",
    "    A 17 18|||S|||榨|||REQUIRED|||-NONE-|||0\n",
    "    A 38 39|||S|||六|||REQUIRED|||-NONE-|||0\n",
    "    A 43 44|||S|||四 量杯|||REQUIRED|||-NONE-|||0\n",
    "    A 49 50|||S|||十|||REQUIRED|||-NONE-|||0\n",
    "    ```\n",
    "    \"\"\"\n",
    "    max_unchanged_words = 2\n",
    "    beta = 0.5\n",
    "    ignore_whitespace_casing = False\n",
    "    very_verbose = False\n",
    "\n",
    "    # load source sentences and gold edits\n",
    "    source_sentences, gold_edits = load_annotation(label_file)\n",
    "\n",
    "    # load system hypotheses\n",
    "    fin = smart_open(prediction_file, \"r\")\n",
    "    system_sentences = [line.strip() for line in fin.readlines()]\n",
    "    fin.close()\n",
    "\n",
    "    p, r, f1 = levenshtein.batch_multi_pre_rec_f1(\n",
    "        system_sentences,\n",
    "        source_sentences,\n",
    "        gold_edits,\n",
    "        max_unchanged_words,\n",
    "        beta,\n",
    "        ignore_whitespace_casing,\n",
    "        verbose,\n",
    "        very_verbose,\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        \"Precision\": p,\n",
    "        \"Recall\": r,\n",
    "        \"F_{}\".format(beta): f1\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# 如果需要测试函数，可以调用它并打印结果\n",
    "if __name__ == \"__main__\":\n",
    "    prediction_file = (this_directory/\"../data/test_prediction_file_correct.txt\").as_posix()\n",
    "    label_file = (this_directory/\"../data/test_label_file.txt\").as_posix()\n",
    "    metrics = maxmatch_metric(prediction_file, label_file)\n",
    "    print(\"Metrics:\", metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5839105a",
   "metadata": {},
   "source": [
    "![alt text](image-10.png)\n",
    "\n",
    "看来实现是正确的，而且我们还能看到详细的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "source": [
    "## 数据加载\n",
    "\n",
    "我们看下 util.py 文件\n",
    "\n",
    "助教这一次已经帮我们完美实现了 GECDataset 类，除了有些类型标注不严谨的问题，这里我们不修改已有的成熟代码，因为可以跑通。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc0eef",
   "metadata": {},
   "source": [
    "## Encoder-Decoder 实现\n",
    "\n",
    "我们首先复习一下课件\n",
    "\n",
    "![alt text](image-11.png)\n",
    "\n",
    "![alt text](image-12.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1362fd92",
   "metadata": {},
   "source": [
    "注意似乎和我更熟悉的 Transformer的 Encoder-Decoder 结构有点不一样。\n",
    "这里是encoder得到单个 context vector, 然后 decoder 直接用这个 context vector 来进行预测。\n",
    "\n",
    "而在Transformer模型中，Encoder通过交叉注意力机制（Cross-Attention）​将信息传递给Decoder。\n",
    "\n",
    "![alt text](image-13.png)\n",
    "\n",
    "Encoder得到了 N个D维输出（token数量），这些输出被Decoder的Cross Attention层使用，会产生 Key 和 Value 被使用。 Transformer论文这部分讲得不清不楚。\n",
    "\n",
    "实际上每一个decoder层，都会先自己masked attention，然后再和encoder的结果去cross。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7ec322",
   "metadata": {},
   "source": [
    "我们回到课件上讲的 传统 RNN 常用的 Encoder-Decoder，没有很多层。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6639bfa3",
   "metadata": {},
   "source": [
    "### elmo 怎么用？\n",
    "我们直接开始写，首先类型注释缺乏 elmo_model 的 类型，我们打开 https://github.com/\n",
    "HIT-SCIR/ELMoForManyLangs 标注为 Embedder, 因为 main 里面是\n",
    "```python\n",
    "elmo_model = Embedder(\"zhs.model\", batch_size=16)\n",
    "\n",
    "```\n",
    "\n",
    "随后有个重要的问题，elmo的embed的维度是多少？我们看了  7.中文语法错误纠正的作业/zhs.model/config.json 引用的 7.中文语法错误纠正的作业/ELMoForManyLangs/elmoformanylangs/configs/cnn_50_100_512_4096_sample.json 才知道是 512， 但是实际上有掉进坑里面了，实际上是1024\n",
    "\n",
    "ELMoForManyLangs 我们查看那源代码发现是不太方便学习的，是个 object，我们需要自己同步tensor 的 device。\n",
    "\n",
    "\n",
    "### GRU 怎么用？\n",
    "然后的问题是 GRU， https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "\n",
    "我搞懂了多层 GRU 原来是从下层的ht作为xt往上传，这里没有额外的产生网络。\n",
    "\n",
    "\n",
    "现在我们来特别学习这个函数，\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_packed_sequence.html， \n",
    "它的作用是将填充后的序列打包成一个 PackedSequence 对象。这样做的好处是可以在 RNN 模型（例如 LSTM 或 GRU）中，只对有效的时间步进行计算，从而提高效率并避免填充部分对模型计算的干扰。\n",
    "\n",
    "source_mask 是一个二值化的张量，用于指示每个序列中的有效位置（例如，1 表示有效，0 表示填充）。通过在维度1上求和，得到每个序列有效元素的个数，即序列真实的长度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f919b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elmoformanylangs import Embedder\n",
    "def encode(\n",
    "        self,\n",
    "        source_inputs: List[List[str]],  # a list of input text\n",
    "        source_mask: torch.Tensor,  # size (batch_size, sequence_length)\n",
    "        **kwargs,\n",
    "    ) -> (\n",
    "        torch.Tensor\n",
    "    ):  # encoder_outputs, size (batch_size, sequence_length, hidden_states)\n",
    "        \"\"\"\n",
    "        Encode input source text, using source_mask to pack padded sequences.\n",
    "        \"\"\"\n",
    "        # Encode the source inputs using ELMo\n",
    "        device = next(self.parameters()).device\n",
    "        with torch.no_grad():\n",
    "            elmo_outputs = self.elmo.sents2elmo(source_inputs)\n",
    "            elmo_outputs = torch.FloatTensor(elmo_outputs).to(device)\n",
    "        # Compute lengths from source_mask (assumes mask with 1 for valid tokens)\n",
    "        lengths = source_mask.sum(dim=1)\n",
    "        # Pack the padded sequence using the computed lengths\n",
    "        packed_input = pack_padded_sequence(\n",
    "            elmo_outputs, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        # Apply the encoder GRU\n",
    "        packed_outputs, _ = self.encoder_gru(packed_input)\n",
    "        # Unpack the sequence\n",
    "        encoder_outputs, _ = pad_packed_sequence(packed_outputs, batch_first=True)\n",
    "        return encoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcb60b0",
   "metadata": {},
   "source": [
    "### Seq2Seq Attention\n",
    "\n",
    "除了老师课件，我们还阅读了 https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "\n",
    "与 https://github.com/PatrickSVM/Seq2Seq-with-Attention/blob/main/seq2seq_attention/model.py\n",
    "\n",
    "我们实际上使用的Attention是 nn.MultiheadAttention, 而不是课上学习的 Additive Attention。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a38191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e3304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb6da022",
   "metadata": {},
   "source": [
    "## Beam Search 实现\n",
    "\n",
    "在训练阶段，可以直接用ground truth的token 作为上一个时刻预测出来的token，这就是所谓的 teacher forcing。刚才代码里面是在 target_input_ids, target_inputs, target_mask 指定的。\n",
    "\n",
    "推理阶段，局部top 1 贪心可能不是最优的，可能累计误差，所以需要 beam search。\n",
    "\n",
    "beam search 保留每个时刻的top k个单词，然后下一个时刻使用这K个可能生成 K*L 个概率，其中选择 top K的作为下一个时刻的输出。\n",
    "\n",
    "当我们实际写代码的时候，发现这个说法稍微有些不准确。实际上不是单词的概率，而是累计到那个位置序列的概率。\n",
    "\n",
    "\n",
    "在开始写代码前要搞懂输入输出类型。\n",
    "\n",
    "\n",
    "| **文件**   | **调用位置** | **方法** | **传入参数** | **参数类型** | **参数含义** |\n",
    "|------------|--------------|----------|--------------|--------------|--------------|\n",
    "| `main.py`  | 模型初始化   | `GECModel` 构造函数 | `elmo_model`<br>`len(vocab_dict)` | `Embedder`<br>`int` | ELMo模型实例<br>词汇表大小 |\n",
    "| `main.py`  | 训练循环     | `model(**batch)` | `batch` | `Dict[str, Tensor]` | 包含输入数据的字典，键为 `\"source_input_ids\"`, `\"source_mask\"`, `\"target_input_ids\"` 等 |\n",
    "| `main.py`  | 测试循环     | `generator.generate(**batch)` | `batch` | `Dict[str, Tensor]` | 包含输入数据的字典，键为 `\"source_input_ids\"`, `\"source_mask\"` 等 |\n",
    "| `main.py`  | 模型初始化   | `BeamSearchGenerator` 构造函数 | `model`<br>`reverse_vocab_dict`<br>`device` | `GECModel`<br>`Dict[int, str]`<br>`str` | GEC模型实例<br>反向词汇表<br>设备（如 `\"cuda:0\"` 或 `\"cpu\"`） |\n",
    "\n",
    "\n",
    "  - `batch`：类型为 `Dict[str, Tensor]`，是一个字典，包含以下键：\n",
    "    - `\"source_input_ids\"`：源文本的输入ID，形状为 `(batch_size, seq_length)`。\n",
    "    - `\"source_mask\"`：源文本的掩码，形状为 `(batch_size, seq_length)`。\n",
    "    - `\"target_input_ids\"`：目标文本的输入ID，形状为 `(batch_size, seq_length)`。\n",
    "    - `\"target_mask\"`：目标文本的掩码，形状为 `(batch_size, seq_length)`。\n",
    "    - `\"labels\"`：目标文本的标签，形状为 `(batch_size, seq_length)`。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b428e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchGenerator:\n",
    "    def __init__(self, model: GECModel, # model.py 定义的模型\n",
    "                 reverse_vocab_dict:Dict[int, str], # elmo 词典\n",
    "                 device:str):\n",
    "        self.oov_index = 0\n",
    "        self.bos_index = 1\n",
    "        self.eos_index = 2\n",
    "        self.pad_index = 3\n",
    "        self.model = model\n",
    "        self.max_length = 200\n",
    "        self.num_beams = 8\n",
    "        self.length_penalty = 0.7\n",
    "        self.vocab = reverse_vocab_dict\n",
    "        self.vocab_size = len(reverse_vocab_dict) # 也就是 L 的大小。\n",
    "        self.device = device\n",
    "\n",
    "    def generate(self, source_mask, \n",
    "                 **kwargs):\n",
    "        encoder_outputs = self.model.encode(**kwargs)\n",
    "        generated_sequence = self.beam_search(encoder_outputs, source_mask)\n",
    "        generated_string = [\n",
    "            re.sub(\n",
    "                \"<bos>|<eos>|<pad>\",\n",
    "                \"\",\n",
    "                \" \".join(list(map(self.vocab.__getitem__, item.tolist()))),\n",
    "            )\n",
    "            for i, item in enumerate(generated_sequence.detach().cpu())\n",
    "        ]\n",
    "        generated_string = [\n",
    "            re.sub(r\"\\s+\", \" \", item.strip()) for item in generated_string\n",
    "        ]\n",
    "        return generated_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd4a4f7",
   "metadata": {},
   "source": [
    "说实话，beam search是这次作业最难的部分。\n",
    "需要处理很多难点逻辑。\n",
    "\n",
    "其中最难的就是和model之间的交互关系。\n",
    "\n",
    "而且原本的 main.py 和 model.py 对于decode 的接口设计有问题，我们有 hidden_states =None, 这是一个重要的参数，但是decode 没有返回新的hidden_states, 这就导致我们在beam search的时候，无法使用上一个时刻的 hidden_states 来进行计算，会减慢速度。\n",
    "\n",
    "我们重新设计了整个接口，结合多个网络代码和AI生成的代码，终于把正确的 beam search实现了出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(\n",
    "    self,\n",
    "    encoder_output: torch.Tensor,  # shape (batch_size, sequence_length, hidden_size) representing the encoder output\n",
    "    source_mask: torch.Tensor,  # shape (batch_size, sequence_length) representing the input mask\n",
    ") -> torch.Tensor:  # int ids, shape (batch_size, max_length)\n",
    "    \"\"\"\n",
    "    perform beam search to get the generated sequence with the highest score\n",
    "    \"\"\"\n",
    "    # 0. get necessary info\n",
    "    batch_size, seq_length, hidden_size = encoder_output.shape\n",
    "    num_beams = self.num_beams\n",
    "    vocab_size = self.vocab_size\n",
    "    max_length = self.max_length\n",
    "\n",
    "    # 1. prepare the encoder output and source mask\n",
    "    encoder_output = einops.repeat(\n",
    "        encoder_output, \"b s h -> (b n) s h\", n=num_beams\n",
    "    )\n",
    "    source_mask = einops.repeat(source_mask, \"b s -> (b n) s\", n=num_beams)\n",
    "\n",
    "    # 2. 初始化为(batch*beam, 1)格式, storing the top-`num_beams` generated sequence\n",
    "    sequence = torch.full(\n",
    "        (batch_size * num_beams, 1),\n",
    "        self.bos_index,  # 填满这个 begin of sentence\n",
    "        dtype=torch.long,\n",
    "        device=self.device,\n",
    "    )\n",
    "    # 3. beam scores, corresponding scores at current timestep\n",
    "    beam_scores = torch.zeros(batch_size, num_beams, device=self.device)\n",
    "    beam_scores[:, 1:] = -1e9\n",
    "    beam_scores = beam_scores.view(-1)\n",
    "\n",
    "    # 4. a flag tensor indicating whether generation is done for current sentence\n",
    "    finished = torch.zeros(batch_size, dtype=torch.bool, device=self.device)\n",
    "    hypotheses = [\n",
    "        BeamHypotheses(num_beams, self.length_penalty) for _ in range(batch_size)\n",
    "    ]\n",
    "    hidden_states = None  # 有点奇怪\n",
    "\n",
    "    # Beam search loop\n",
    "    for cur_len in range(1, max_length):\n",
    "        # Get decoder output\n",
    "        decoder_output, new_hidden_states = self.model.decode(\n",
    "            encoder_outputs=encoder_output,\n",
    "            source_mask=source_mask,\n",
    "            target_input_ids=sequence,\n",
    "            target_mask=torch.ones_like(sequence).to(self.device),\n",
    "            hidden_states=hidden_states\n",
    "        )\n",
    "\n",
    "        # Get logits for the next token\n",
    "        logits = decoder_output[:, -1, :]  # (batch_size * num_beams, vocab_size)\n",
    "        log_probs = torch.log_softmax(logits, dim=-1)\n",
    "\n",
    "        # Add log_probs to beam_scores\n",
    "        next_scores = beam_scores.unsqueeze(-1) + log_probs  # (batch_size * num_beams, vocab_size)\n",
    "        next_scores = next_scores.view(batch_size, num_beams * vocab_size)\n",
    "\n",
    "        # Get top k scores and indices\n",
    "        next_scores, next_indices = torch.topk(next_scores, num_beams, dim=1)\n",
    "        next_beam_indices = next_indices // vocab_size\n",
    "        next_token_indices = next_indices % vocab_size\n",
    "\n",
    "        # Update beam_scores\n",
    "        beam_scores = next_scores.view(-1)\n",
    "\n",
    "        # Update sequence\n",
    "        sequence = sequence[next_beam_indices.view(-1)]\n",
    "        sequence = torch.cat(\n",
    "            [sequence, next_token_indices.view(-1, 1)], dim=1\n",
    "        )\n",
    "\n",
    "        # Update hidden states\n",
    "        if new_hidden_states is not None:\n",
    "            hidden_states = new_hidden_states[:, next_beam_indices.view(-1), :]\n",
    "            # hidden_states = new_hidden_states\n",
    "\n",
    "        # Check for EOS tokens\n",
    "        eos_in_beam = (next_token_indices == self.eos_index).any(dim=1)\n",
    "        for i in range(batch_size):\n",
    "            if eos_in_beam[i].any():\n",
    "                beam_idx = i * num_beams\n",
    "                for j in range(num_beams):\n",
    "                    if beam_idx + j < next_token_indices.size(0) and next_token_indices[beam_idx + j] == self.eos_index:\n",
    "                        hypotheses[i].add(\n",
    "                            sequence[beam_idx + j].clone(),\n",
    "                            beam_scores[beam_idx + j].item()\n",
    "                        )\n",
    "                if len(hypotheses[i]) >= num_beams:\n",
    "                    finished[i] = True\n",
    "\n",
    "        if finished.all():\n",
    "            break\n",
    "\n",
    "    # Get the best sequence from hypotheses\n",
    "    best_sequences = []\n",
    "    for i in range(batch_size):\n",
    "        if len(hypotheses[i]) > 0:\n",
    "            best_sequences.append(hypotheses[i].beams[-1][0])\n",
    "        else:\n",
    "            best_sequences.append(sequence[i * num_beams])\n",
    "\n",
    "    # Pad sequences to max_length\n",
    "    output_sequence = torch.full(\n",
    "        (batch_size, max_length), self.eos_index, dtype=torch.long, device=self.device\n",
    "    )\n",
    "    for i, seq in enumerate(best_sequences):\n",
    "        seq_len = min(len(seq), max_length)\n",
    "        output_sequence[i, :seq_len] = seq[:seq_len]\n",
    "\n",
    "    return output_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e21590",
   "metadata": {},
   "source": [
    "## RWKV 实现\n",
    "\n",
    "RWKV 是 目前较为先进的RNN模型，号称结合了 Attention 并行训练和长文本建模的能力和RNN高效推理无限上下文长度的能力。RWKV 本质上和LSTM一样都是RNN模型，只是其使用了不同的激活函数和门控机制以及其他的一些高级操作。\n",
    "\n",
    "感觉RWKV的开源做的很好，在linux基金会下 https://rwkv.cn/news/read?id=15 ，看起来很有前景。\n",
    "\n",
    "RWKV-LM 的开源代码很复杂，有cuda kernel c++啥的，很难改。通过和RWKV社区成员沟通交流，发现这个https://github.com/TorchRWKV/flash-linear-attention/tree/stable 实现比较优雅，用torch写，但是用triton编译。\n",
    "\n",
    "我们安装一下。\n",
    "\n",
    "```bash\n",
    "pip install -U git+https://github.com/TorchRWKV/flash-linear-attention\n",
    "```\n",
    "\n",
    "看源码 https://github.com/TorchRWKV/flash-linear-attention/blob/stable/fla/layers/rwkv7.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597d591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入 RWKV7Attention 模块\n",
    "from fla.layers.rwkv7 import RWKV7Attention\n",
    "rwkv = RWKV7Attention(mode=\"chunk\", hidden_size=vector_size, head_dim=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa0390",
   "metadata": {},
   "source": [
    "## 运行效果\n",
    "\n",
    "### 跑通前其他报错\n",
    "\n",
    "![alt text](image-14.png)\n",
    "\n",
    "这个错误来自 ELMoForManyLangs 库的 Highway 类的实现问题。看起来是 Python 3.12 的类型检查更严格了，导致 overrides 装饰器检查失败。我们需要修复 highway.py 文件中的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660d1195",
   "metadata": {},
   "source": [
    "![alt text](image-15.png)\n",
    "\n",
    "这个错误是因为 外面的 util和里面的util重名了（我们刚才强行使用sys把m2scorer加入到解释器路径中）。\n",
    "按照thu-cvml 命名规范，我们把外面的改成infra.py 而不是 util.py 避免冲突"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e214573d",
   "metadata": {},
   "source": [
    "/home/ycm/repos/coursework/THU-Coursework-Knowledge-Engineering/7.中文语法错误纠正的作业/main.py:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
    "  with autocast():"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0743f8b1",
   "metadata": {},
   "source": [
    "### 训练准确率\n",
    "\n",
    "![alt text](image-16.png)\n",
    "\n",
    "可以看到GRU模型的准确率随着epoch进行逐渐上升, 从 35 上升到了 65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766659d9",
   "metadata": {},
   "source": [
    "![alt text](image-17.png)\n",
    "\n",
    "RWKV 报错，由于时间不足，我们下次再跑。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9426c73",
   "metadata": {},
   "source": [
    "beam search 可以运行，但是速度太慢了，我们把它从训练代码中去除了，否则需要跑很多小时才能跑出来\n",
    "\n",
    "![alt text](image-18.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565e0813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a1b41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f56d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
